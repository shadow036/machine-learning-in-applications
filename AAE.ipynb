{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "try:\n",
    "    # enable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type == 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DATA_DIR_SLOW = \"/Users/kedi/Desktop/polito lectures and notes/ML in App/project/KukaVelocityDataset/KukaSlow.npy\"\n",
    "DATA_DIR_NORMAL = \"/Users/kedi/Desktop/polito lectures and notes/ML in App/project/KukaVelocityDataset/KukaNormal.npy\"\n",
    "DATA_DIR_C_NAMES = \"/Users/kedi/Desktop/polito lectures and notes/ML in App/project/KukaVelocityDataset/KukaColumnNames.npy\"\n",
    "\n",
    "# Set style for matplotlib\n",
    "plt.style.use(\"Solarize_Light2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_normal = np.load(DATA_DIR_NORMAL)\n",
    "data_slow = np.load(DATA_DIR_SLOW)\n",
    "column_names = np.load(DATA_DIR_C_NAMES)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['action' 'machine_nameKuka Robot_apparent_power'\n",
      " 'machine_nameKuka Robot_current' 'machine_nameKuka Robot_frequency'\n",
      " 'machine_nameKuka Robot_phase_angle' 'machine_nameKuka Robot_power'\n",
      " 'machine_nameKuka Robot_power_factor'\n",
      " 'machine_nameKuka Robot_reactive_power' 'machine_nameKuka Robot_voltage'\n",
      " 'sensor_id1_AccX' 'sensor_id1_AccY' 'sensor_id1_AccZ' 'sensor_id1_GyroX'\n",
      " 'sensor_id1_GyroY' 'sensor_id1_GyroZ' 'sensor_id1_q1' 'sensor_id1_q2'\n",
      " 'sensor_id1_q3' 'sensor_id1_q4' 'sensor_id1_temp' 'sensor_id2_AccX'\n",
      " 'sensor_id2_AccY' 'sensor_id2_AccZ' 'sensor_id2_GyroX' 'sensor_id2_GyroY'\n",
      " 'sensor_id2_GyroZ' 'sensor_id2_q1' 'sensor_id2_q2' 'sensor_id2_q3'\n",
      " 'sensor_id2_q4' 'sensor_id2_temp' 'sensor_id3_AccX' 'sensor_id3_AccY'\n",
      " 'sensor_id3_AccZ' 'sensor_id3_GyroX' 'sensor_id3_GyroY'\n",
      " 'sensor_id3_GyroZ' 'sensor_id3_q1' 'sensor_id3_q2' 'sensor_id3_q3'\n",
      " 'sensor_id3_q4' 'sensor_id3_temp' 'sensor_id4_AccX' 'sensor_id4_AccY'\n",
      " 'sensor_id4_AccZ' 'sensor_id4_GyroX' 'sensor_id4_GyroY'\n",
      " 'sensor_id4_GyroZ' 'sensor_id4_q1' 'sensor_id4_q2' 'sensor_id4_q3'\n",
      " 'sensor_id4_q4' 'sensor_id4_temp' 'sensor_id5_AccX' 'sensor_id5_AccY'\n",
      " 'sensor_id5_AccZ' 'sensor_id5_GyroX' 'sensor_id5_GyroY'\n",
      " 'sensor_id5_GyroZ' 'sensor_id5_q1' 'sensor_id5_q2' 'sensor_id5_q3'\n",
      " 'sensor_id5_q4' 'sensor_id5_temp' 'sensor_id6_AccX' 'sensor_id6_AccY'\n",
      " 'sensor_id6_AccZ' 'sensor_id6_GyroX' 'sensor_id6_GyroY'\n",
      " 'sensor_id6_GyroZ' 'sensor_id6_q1' 'sensor_id6_q2' 'sensor_id6_q3'\n",
      " 'sensor_id6_q4' 'sensor_id6_temp' 'sensor_id7_AccX' 'sensor_id7_AccY'\n",
      " 'sensor_id7_AccZ' 'sensor_id7_GyroX' 'sensor_id7_GyroY'\n",
      " 'sensor_id7_GyroZ' 'sensor_id7_q1' 'sensor_id7_q2' 'sensor_id7_q3'\n",
      " 'sensor_id7_q4' 'sensor_id7_temp' 'anomaly']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "# Normalization train on train set transform both\n",
    "scaler = preprocessing.StandardScaler().fit(data_normal)\n",
    "data_train_scaled = scaler.transform(data_normal)\n",
    "data_test_scaled = scaler.transform(data_slow[:,:-1]) #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (233742, 50, 86) \n",
      " test data shape: (41488, 50, 86) \n"
     ]
    }
   ],
   "source": [
    "#windows of 50 with stride\n",
    "width_window = 50\n",
    "data_train = np.array([data_train_scaled[i:i+width_window,:] for i in range(0, len(data_train_scaled)-width_window)])\n",
    "data_test = np.array([data_test_scaled[i:i+width_window,:] for i in range(0, len(data_test_scaled)-width_window)])\n",
    "print(f\"train data shape: {data_train.shape} \\n test data shape: {data_test.shape} \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (23379, 50, 86) \n",
      " test data shape: (4153, 50, 86) \n"
     ]
    }
   ],
   "source": [
    "# take part of data to gather results faster\n",
    "percentage = 0.10\n",
    "data_train = data_train[0:int(percentage*data_train_scaled.shape[0]),:]\n",
    "data_test = data_test[0:int(percentage*data_test_scaled.shape[0]),:]\n",
    "print(f\"train data shape: {data_train.shape} \\n test data shape: {data_test.shape} \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_buf = 60000\n",
    "comment = False\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(data_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "def make_encoder_model(z_size):\n",
    "    inputs = tf.keras.layers.Input(shape=(50, 86))\n",
    "    if comment is True : print(f\"encoder input: {inputs.shape}\")\n",
    "    x = tf.keras.layers.Conv1D(filters=128, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=128, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=256, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=256, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=256, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    z = tf.keras.layers.Conv1D(filters=z_size, kernel_size=7, strides=2, padding='same')(x)\n",
    "    if comment is True : print(f\"endoder output: {z.shape}\")\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=z)\n",
    "    return model\n",
    "\n",
    "def make_decoder_model(z_size):\n",
    "    encoded = tf.keras.Input(shape=(1, z_size))\n",
    "    if comment is True : print(f\"decoder input: {encoded.shape}\")\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(256, kernel_size=7, padding='same', activation='relu')(encoded)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "    x = tf.keras.layers.Conv1D(256, kernel_size=7, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "    x = tf.keras.layers.Conv1D(256, kernel_size=7, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "    x = tf.keras.layers.Conv1D(128, kernel_size=7, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "    x = tf.keras.layers.Conv1D(128, kernel_size=7, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "    x = tf.keras.layers.Conv1D(86, kernel_size=7, activation='relu')(x)\n",
    "    x = tf.keras.layers.UpSampling1D(2)(x)\n",
    "\n",
    "    reconstruction = tf.keras.layers.Conv1D(filters=86, kernel_size=3, activation='sigmoid')(x)\n",
    "    if comment is True : print(f\"decoder output: {reconstruction.shape}\")\n",
    "    decoder = tf.keras.Model(inputs=encoded, outputs=reconstruction)\n",
    "    return decoder\n",
    "\n",
    "def make_discriminator_model(z_size):\n",
    "    encoded = tf.keras.Input(shape=(1, z_size))\n",
    "    if comment is True : print(f\"discriminator input: {encoded.shape}\")\n",
    "    x = tf.keras.layers.Dense(128)(encoded)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    prediction = tf.keras.layers.Dense(1)(x)\n",
    "    if comment is True : print(f\"discriminator output: {prediction.shape}\")\n",
    "    model = tf.keras.Model(inputs=encoded, outputs=prediction)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "z_dim = 512\n",
    "with tf.device('/GPU:0'):\n",
    "    encoder = make_encoder_model(z_dim)\n",
    "    decoder = make_decoder_model(z_dim)\n",
    "    discriminator = make_discriminator_model(z_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "ae_loss_weight = 1.\n",
    "gen_loss_weight = 1.\n",
    "dc_loss_weight = 1.\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    accuracy = tf.keras.metrics.BinaryAccuracy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def autoencoder_loss(inputs, reconstruction, loss_weight):\n",
    "    return loss_weight * mse(inputs, reconstruction)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_output, fake_output, loss_weight):\n",
    "    loss_real = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    loss_fake = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return loss_weight * (loss_fake + loss_real)\n",
    "\n",
    "\n",
    "def generator_loss(fake_output, loss_weight):\n",
    "    return loss_weight * cross_entropy(tf.ones_like(fake_output), fake_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "base_lr = 0.00025\n",
    "max_lr = 0.0025\n",
    "\n",
    "n_samples = data_train.shape[0]\n",
    "step_size = 2 * np.ceil(n_samples / batch_size)\n",
    "global_step = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    ae_optimizer = tf.keras.optimizers.Adam(learning_rate=base_lr)\n",
    "    dc_optimizer = tf.keras.optimizers.Adam(learning_rate=base_lr)\n",
    "    gen_optimizer = tf.keras.optimizers.Adam(learning_rate=base_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def train_step(batch_x):\n",
    "    with tf.device('/GPU:0'):\n",
    "        # -------------------------------------------------------------------------------------------------------------\n",
    "        # Autoencoder\n",
    "        with tf.GradientTape() as ae_tape:\n",
    "            encoder_output = encoder(batch_x, training=True)\n",
    "            decoder_output = decoder(encoder_output, training=True)\n",
    "\n",
    "            if comment is True : print(f\"Train step: \\nbatch_x: {batch_x.shape}, decoder_output: {decoder_output.shape}\")\n",
    "            # Autoencoder loss\n",
    "            ae_loss = autoencoder_loss(batch_x, decoder_output, ae_loss_weight)\n",
    "\n",
    "        ae_grads = ae_tape.gradient(ae_loss, encoder.trainable_variables + decoder.trainable_variables)\n",
    "        ae_optimizer.apply_gradients(zip(ae_grads, encoder.trainable_variables + decoder.trainable_variables))\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------------\n",
    "        # Discriminator\n",
    "        with tf.GradientTape() as dc_tape:\n",
    "            real_distribution = tf.random.normal([batch_x.shape[0], 1, z_dim], mean=0.0, stddev=1.0)\n",
    "            encoder_output = encoder(batch_x, training=True)\n",
    "\n",
    "            dc_real = discriminator(real_distribution, training=True)\n",
    "            dc_fake = discriminator(encoder_output, training=True)\n",
    "\n",
    "            # Discriminator Loss\n",
    "            dc_loss = discriminator_loss(dc_real, dc_fake, dc_loss_weight)\n",
    "\n",
    "            # Discriminator Acc\n",
    "            dc_acc = accuracy(tf.concat([tf.ones_like(dc_real), tf.zeros_like(dc_fake)], axis=0),\n",
    "                              tf.concat([dc_real, dc_fake], axis=0))\n",
    "\n",
    "        dc_grads = dc_tape.gradient(dc_loss, discriminator.trainable_variables)\n",
    "        dc_optimizer.apply_gradients(zip(dc_grads, discriminator.trainable_variables))\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------------\n",
    "        # Generator (Encoder)\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            encoder_output = encoder(batch_x, training=True)\n",
    "            dc_fake = discriminator(encoder_output, training=True)\n",
    "\n",
    "            # Generator loss\n",
    "            gen_loss = generator_loss(dc_fake, gen_loss_weight)\n",
    "\n",
    "        gen_grads = gen_tape.gradient(gen_loss, encoder.trainable_variables)\n",
    "        gen_optimizer.apply_gradients(zip(gen_grads, encoder.trainable_variables))\n",
    "\n",
    "        return ae_loss, dc_loss, dc_acc, gen_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0: TIME: 61.78 ETA: 6178.24 AE_LOSS: 1.0766 DC_LOSS: 3.5214 DC_ACC: 0.2972 GEN_LOSS: 2.3127\n",
      "   1: TIME: 59.95 ETA: 5935.42 AE_LOSS: 1.0393 DC_LOSS: 1.8571 DC_ACC: 0.4002 GEN_LOSS: 1.9941\n",
      "   2: TIME: 59.50 ETA: 5831.23 AE_LOSS: 1.0379 DC_LOSS: 1.1423 DC_ACC: 0.4812 GEN_LOSS: 3.4687\n",
      "   3: TIME: 60.00 ETA: 5819.82 AE_LOSS: 1.0380 DC_LOSS: 1.0224 DC_ACC: 0.5592 GEN_LOSS: 1.6385\n",
      "   4: TIME: 60.17 ETA: 5776.49 AE_LOSS: 1.0381 DC_LOSS: 0.9180 DC_ACC: 0.6092 GEN_LOSS: 1.8378\n",
      "   5: TIME: 59.56 ETA: 5658.57 AE_LOSS: 1.0380 DC_LOSS: 1.6868 DC_ACC: 0.6330 GEN_LOSS: 2.6973\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/br/qj7m3b896ql0xqb6tcyln95c0000gn/T/ipykernel_6372/2482000768.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m     25\u001B[0m             \u001B[0mae_optimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0mdc_optimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m             \u001B[0mgen_optimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m             \u001B[0mae_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdc_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdc_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgen_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_x\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m             \u001B[0mepoch_ae_loss_avg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mae_loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m             \u001B[0mepoch_dc_loss_avg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdc_loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/br/qj7m3b896ql0xqb6tcyln95c0000gn/T/ipykernel_6372/2637019201.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(batch_x)\u001B[0m\n\u001B[1;32m      9\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mcomment\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mTrue\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Train step: \\nbatch_x: {batch_x.shape}, decoder_output: {decoder_output.shape}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m             \u001B[0;31m# Autoencoder loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m             \u001B[0mae_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mautoencoder_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecoder_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mae_loss_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m         \u001B[0mae_grads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mae_tape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mae_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mdecoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m         \u001B[0mae_optimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mae_grads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mdecoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0;31m# -------------------------------------------------------------------------------------------------------------\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tensor_gpu/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m   1096\u001B[0m               output_gradients))\n\u001B[1;32m   1097\u001B[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001B[1;32m   1098\u001B[0m                           for x in output_gradients]\n\u001B[1;32m   1099\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1100\u001B[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001B[0m\u001B[1;32m   1101\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1102\u001B[0m         \u001B[0mflat_targets\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1103\u001B[0m         \u001B[0mflat_sources\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tensor_gpu/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[1;32m     63\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m     raise ValueError(\n\u001B[1;32m     65\u001B[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001B[0m\u001B[1;32m     68\u001B[0m       \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m       \u001B[0msources\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tensor_gpu/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[1;32m    153\u001B[0m     \u001B[0mgradient_name_scope\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"gradient_tape/\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m       \u001B[0mgradient_name_scope\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgradient_name_scope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 157\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    158\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tensor_gpu/lib/python3.10/site-packages/tensorflow/python/ops/nn_grad.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(op, grad)\u001B[0m\n\u001B[1;32m    573\u001B[0m   \u001B[0;31m# to use the nn_ops functions, we would have to convert `padding` and\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m   \u001B[0;31m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    575\u001B[0m   \u001B[0;31m# in Eager mode.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    576\u001B[0m   return [\n\u001B[0;32m--> 577\u001B[0;31m       gen_nn_ops.conv2d_backprop_input(\n\u001B[0m\u001B[1;32m    578\u001B[0m           \u001B[0mshape_0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    579\u001B[0m           \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m           \u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tensor_gpu/lib/python3.10/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001B[0m\n\u001B[1;32m   1244\u001B[0m         data_format, \"dilations\", dilations)\n\u001B[1;32m   1245\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1246\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1247\u001B[0m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1248\u001B[0;31m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1249\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1250\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1251\u001B[0m       return conv2d_backprop_input_eager_fallback(\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    n_epochs = 100\n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        # Learning rate schedule\n",
    "        if epoch in [60, 100, 300]:\n",
    "            base_lr = base_lr / 2\n",
    "            max_lr = max_lr / 2\n",
    "            step_size = step_size / 2\n",
    "\n",
    "            print('learning rate changed!')\n",
    "\n",
    "        epoch_ae_loss_avg = tf.metrics.Mean()\n",
    "        epoch_dc_loss_avg = tf.metrics.Mean()\n",
    "        epoch_dc_acc_avg = tf.metrics.Mean()\n",
    "        epoch_gen_loss_avg = tf.metrics.Mean()\n",
    "        for batch, (batch_x) in enumerate(train_dataset):\n",
    "            # -------------------------------------------------------------------------------------------------------------\n",
    "            # Calculate cyclic learning rate\n",
    "            global_step = global_step + 1\n",
    "            cycle = np.floor(1 + global_step / (2 * step_size))\n",
    "            x_lr = np.abs(global_step / step_size - 2 * cycle + 1)\n",
    "            clr = base_lr + (max_lr - base_lr) * max(0, 1 - x_lr)\n",
    "            ae_optimizer.lr = clr\n",
    "            dc_optimizer.lr = clr\n",
    "            gen_optimizer.lr = clr\n",
    "\n",
    "            ae_loss, dc_loss, dc_acc, gen_loss = train_step(batch_x)\n",
    "\n",
    "            epoch_ae_loss_avg(ae_loss)\n",
    "            epoch_dc_loss_avg(dc_loss)\n",
    "            epoch_dc_acc_avg(dc_acc)\n",
    "            epoch_gen_loss_avg(gen_loss)\n",
    "\n",
    "        epoch_time = time.time() - start\n",
    "        print('{:4d}: TIME: {:.2f} ETA: {:.2f} AE_LOSS: {:.4f} DC_LOSS: {:.4f} DC_ACC: {:.4f} GEN_LOSS: {:.4f}' \\\n",
    "              .format(epoch, epoch_time,\n",
    "                      epoch_time * (n_epochs - epoch),\n",
    "                      epoch_ae_loss_avg.result(),\n",
    "                      epoch_dc_loss_avg.result(),\n",
    "                      epoch_dc_acc_avg.result(),\n",
    "                      epoch_gen_loss_avg.result()))\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        if epoch % 10 == 0:\n",
    "            # Latent Space\n",
    "            x_test_encoded = encoder(x_test, training=False)\n",
    "            label_list = list(y_test)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            classes = set(label_list)\n",
    "            colormap = plt.cm.rainbow(np.linspace(0, 1, len(classes)))\n",
    "            kwargs = {'alpha': 0.8, 'c': [colormap[i] for i in label_list]}\n",
    "            ax = plt.subplot(111, aspect='equal')\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            handles = [mpatches.Circle((0, 0), label=class_, color=colormap[i])\n",
    "                       for i, class_ in enumerate(classes)]\n",
    "            ax.legend(handles=handles, shadow=True, bbox_to_anchor=(1.05, 0.45),\n",
    "                      fancybox=True, loc='center left')\n",
    "            plt.scatter(x_test_encoded[:, :, :, 0], x_test_encoded[:, :, :, 1], s=2, **kwargs)\n",
    "            ax.set_xlim([-3, 3])\n",
    "            ax.set_ylim([-3, 3])\n",
    "\n",
    "            plt.savefig(latent_space_dir / ('epoch_%d.png' % epoch))\n",
    "            plt.close('all')\n",
    "\n",
    "            # Reconstruction\n",
    "            n_digits = 20  # how many digits we will display\n",
    "            x_test_decoded = decoder(encoder(x_test[:n_digits], training=False), training=False)\n",
    "            x_test_decoded = np.reshape(x_test_decoded, [-1, 28, 28]) * 255\n",
    "            fig = plt.figure(figsize=(20, 4))\n",
    "            for i in range(n_digits):\n",
    "                # display original\n",
    "                ax = plt.subplot(2, n_digits, i + 1)\n",
    "                plt.imshow(x_test[i].reshape(28, 28))\n",
    "                plt.gray()\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "\n",
    "                # display reconstruction\n",
    "                ax = plt.subplot(2, n_digits, i + 1 + n_digits)\n",
    "                plt.imshow(x_test_decoded[i])\n",
    "                plt.gray()\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            plt.savefig(reconstruction_dir / ('epoch_%d.png' % epoch))\n",
    "            plt.close('all')\n",
    "\n",
    "            # Sampling\n",
    "            x_points = np.linspace(-3, 3, 20).astype(np.float32)\n",
    "            y_points = np.linspace(-3, 3, 20).astype(np.float32)\n",
    "\n",
    "            nx, ny = len(x_points), len(y_points)\n",
    "            plt.subplot()\n",
    "            gs = gridspec.GridSpec(nx, ny, hspace=0.05, wspace=0.05)\n",
    "\n",
    "            for i, g in enumerate(gs):\n",
    "                z = np.concatenate(([x_points[int(i / ny)]], [y_points[int(i % nx)]]))\n",
    "                z = np.reshape(z, (1, 1, 1, 2))\n",
    "                x = decoder(z, training=False).numpy()\n",
    "                ax = plt.subplot(g)\n",
    "                img = np.array(x.tolist()).reshape(28, 28)\n",
    "                ax.imshow(img, cmap='gray')\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_aspect('auto')\n",
    "            plt.savefig(sampling_dir / ('epoch_%d.png' % epoch))\n",
    "            plt.close('all')\n",
    "        \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}